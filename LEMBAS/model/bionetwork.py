"""
Defines the various layers in the SignalingModel RNN.
"""

from typing import Dict, List, Union, Annotated, Any
from annotated_types import Ge
import copy

import pandas as pd
import numpy as np 
import scipy
from scipy.sparse.linalg import eigs

import torch
import torch.nn as nn
import torch.nn.functional as F

from .model_utilities import np_to_torch, format_network
from .activation_functions import activation_function_map
from ..utilities import set_seeds

class ProjectInput(nn.Module):
    """Generate all nodes for the signaling network and linearly scale input ligand values by NN parameters."""
    def __init__(self, node_idx_map: Dict[str, int], drug_target_map: pd.DataFrame, projection_amplitude: Union[int, float] = 1, dtype: torch.dtype=torch.float32, device: str = 'cpu'):
        """Initialization method.

        Parameters
        ----------
        node_idx_map : Dict[str, int]
            a dictionary mapping node labels (str) to the node index (float)
            generated by `SignalingModel.parse_network`
        drug_target_map : pd.DataFrame
            DataFrame with drug targets as rows and drugs as columns (one-hot encoded)
        projection_amplitude : Union[int, float]
            value with which to initialize learned linear scaling parameters, by default 1. (if turn require_grad = False for this layer, this is still applied simply as a constant linear scalar in each forward pass)
        dtype : torch.dtype, optional
            datatype to store values in torch, by default torch.float32
        device : str
            whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
        """
        super().__init__()

        self.device = device
        self.dtype = dtype
        self.projection_amplitude = projection_amplitude
        self.size_out = len(node_idx_map) # number of nodes total in prior knowledge network
        
        self.drug_target_map = torch.tensor(drug_target_map.values, dtype=self.dtype, device=self.device)
        self.drug_target_map.requires_grad = False  # Fixed weights for this layer
        
        self.input_node_order = torch.tensor([node_idx_map[x] for x in drug_target_map.index], device = self.device) # idx representation of ligand inputs
        weights = self.projection_amplitude * torch.ones(len(drug_target_map.index), dtype=self.dtype, device = self.device) # scaled input weights
        self.weights = nn.Parameter(weights)
        
    def forward(self, X_in: torch.Tensor):
        """Learn the weights for the input drugs to the signaling network (if grad_fn set to False, 
        simply scales by projection amplitude).
        Transform from ligand input (samples x drugs) to full signaling network (samples x network nodes).

        Parameters
        ----------
        X_in : torch.Tensor
            the ligand concentration inputs. Shape is (samples x drugs). 

        Returns
        -------
        X_full :  torch.Tensor
            the linearly scaled ligand inputs. Shape is (samples x network nodes)
        """
        X_drug_targets = torch.matmul(X_in, self.drug_target_map.T)  # Drugs to drug targets, shape of (drug_targets, drugs)
        
        X_full = torch.zeros([X_in.shape[0],  self.size_out], dtype=self.dtype, device=self.device)  # shape of (samples x total nodes in network)
        X_full[:, self.input_node_order] = self.weights * X_drug_targets  # only modify those nodes that are part of the input (drug targets)
        return X_full
    
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        Here, this pushes learned parameters towards `projection_amplitude` 
        
        Parameters
        ----------
        lambda_2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
        
        Returns
        -------
        projection_L2 : torch.Tensor
            the regularization term
        """
        # if removed the `- self.projection_amplitude` part, would force weights to 0, thus shrinking ligand inputs
        projection_L2 = lambda_L2 * torch.sum(torch.square(self.weights - self.projection_amplitude))  
        return projection_L2


class CellLineNetwork(nn.Module):
    """Fully connected network to handle cell line information."""
    def __init__(self, input_dim: int, hidden_layers: Dict[int, int], output_dim: int, dtype: torch.dtype = torch.float32, device: str = 'cpu'):
        """
        Initialization method.

        Parameters
        ----------
        input_dim : int
            Number of input neurons (number of cell lines).
        hidden_layers : Dict[int, int]
            Dictionary specifying the number of hidden layers and their sizes. Keys are layer indices (starting from 1) and values are the number of neurons.
        output_dim : int
            Number of output neurons (same as the shape of the bias in X_bias).
        dtype : torch.dtype, optional
            Datatype to store values in torch, by default torch.float32.
        device : str, optional
            Whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu".
        """
        super().__init__()
        self.device = device
        self.dtype = dtype

        layers = []
        prev_dim = input_dim

        # Add hidden layers if any
        if hidden_layers:
            for i in range(1, len(hidden_layers) + 1):
                layers.append(nn.Linear(prev_dim, hidden_layers[i]).to(device, dtype))
                layers.append(nn.ReLU())
                prev_dim = hidden_layers[i]

        # Add output layer
        layers.append(nn.Linear(prev_dim, output_dim).to(device, dtype))
        self.network = nn.Sequential(*layers)

    def forward(self, X_cell: torch.Tensor):
        """
        Forward pass to compute the bias term.

        Parameters
        ----------
        X_cell : torch.Tensor
            The cell line input tensor. Shape is (samples x cell lines).

        Returns
        -------
        X_bias : torch.Tensor
            The computed bias term. Shape is (samples x output_dim).
        """
        X_bias = self.network(X_cell)
        return X_bias
    
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        reg_loss = 0.0
        for param in self.parameters():
            reg_loss += torch.sum(param ** 2)
        return lambda_L2 * reg_loss
    

class XssCellLineNetwork(nn.Module):
    """Fully connected network to handle cell line information."""
    def __init__(self, input_dim: int, hidden_layers: Dict[int, int], output_dim: int, dtype: torch.dtype = torch.float32, device: str = 'cpu'):
        """
        Initialization method.

        Parameters
        ----------
        input_dim : int
            Number of input neurons (number of cell lines).
        hidden_layers : Dict[int, int]
            Dictionary specifying the number of hidden layers and their sizes. Keys are layer indices (starting from 1) and values are the number of neurons.
        output_dim : int
            Number of output neurons (same as the shape of the bias in X_bias).
        dtype : torch.dtype, optional
            Datatype to store values in torch, by default torch.float32.
        device : str, optional
            Whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu".
        """
        super().__init__()
        self.device = device
        self.dtype = dtype

        layers = []
        prev_dim = input_dim

        # Add hidden layers if any
        if hidden_layers:
            for i in range(1, len(hidden_layers) + 1):
                layers.append(nn.Linear(prev_dim, hidden_layers[i]).to(device, dtype))
                layers.append(nn.ReLU())
                prev_dim = hidden_layers[i]

        # Add output layer
        layers.append(nn.Linear(prev_dim, output_dim).to(device, dtype))
        self.network = nn.Sequential(*layers)

    def forward(self, X_cell: torch.Tensor):
        """
        Forward pass to compute the bias term.

        Parameters
        ----------
        X_cell : torch.Tensor
            The cell line input tensor. Shape is (samples x cell lines).

        Returns
        -------
        X_bias : torch.Tensor
            The computed bias term. Shape is (samples x output_dim).
        """
        X_bias = self.network(X_cell)
        return X_bias
    
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        reg_loss = 0.0
        for param in self.parameters():
            reg_loss += torch.sum(torch.square(param))
        return lambda_L2 * reg_loss


class BioNet(nn.Module):
    """Builds the RNN on the signaling network topology."""
    def __init__(self, edge_list: np.array, 
                 edge_MOA: np.array, 
                 n_network_nodes: int, 
                 bionet_params: Dict[str, float], 
                 activation_function: str = 'MML', 
                 dtype: torch.dtype=torch.float32, 
                 device: str = 'cpu', 
                 seed: int = 888,
                 cell_line_network: CellLineNetwork = None,
                 xss_cell_line_network: XssCellLineNetwork = None):
        """Initialization method.

        Parameters
        ----------
        edge_list : np.array
            a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
            second row represents the indices for the source node. net.shape[0] is the total # of interactions
            output from  `SignalingModel.parse_network` 
        edge_MOA : np.array
            a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
            second row is a boolean of whether the interactions are inhibiting
            output from  `SignalingModel.parse_network`
        n_network_nodes : int
            the number of nodes in the network
        bionet_params : Dict[str, float]
            training parameters for the model
            see `SignalingModel.set_training_parameters`
        activation_function : str, optional
            RNN activation function, by default 'MML'
            options include:
                - 'MML': Michaelis-Menten-like
                - 'leaky_relu': Leaky ReLU
                - 'sigmoid': sigmoid 
        dtype : torch.dtype, optional
           datatype to store values in torch, by default torch.float32
        device : str
            whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
        seed : int
            random seed for torch and numpy operations, by default 888
        use_cell_line_network : bool, optional
            whether to use the cell line network, by default True
        """
        super().__init__()
        self.training_params = bionet_params
        self.dtype = dtype
        self.device = device
        self.seed = seed
        self._ss_seed_counter = 0

        self.n_network_nodes = n_network_nodes
        # TODO: delete these _in _out?
        self.n_network_nodes_in = n_network_nodes
        self.n_network_nodes_out = n_network_nodes

        self.edge_list = (np_to_torch(edge_list[0,:], dtype = torch.int32, device = 'cpu'), 
                          np_to_torch(edge_list[1,:], dtype = torch.int32, device = 'cpu'))
        self.edge_MOA = np_to_torch(edge_MOA, dtype=torch.bool, device = self.device)

        # initialize weights and biases
        weights, bias = self.initialize_weights()
        self.weights = nn.Parameter(weights)
        self.bias = nn.Parameter(bias)

        self.weights_MOA, self.mask_MOA = self.make_mask_MOA() # mechanism of action 

        # activation function
        self.activation = activation_function_map[activation_function]['activation']
        self.delta = activation_function_map[activation_function]['delta']
        self.onestepdelta_activation_factor = activation_function_map[activation_function]['onestepdelta']
        
        self.cell_line_network = cell_line_network
        self.xss_cell_line_network = xss_cell_line_network
        
    def initialize_weight_values(self):
        """Initialize the RNN weight_values for all interactions in the signaling network.

        Returns
        -------
        weight_values : torch.Tensor
            a torch.Tensor with randomly initialized values for each signaling network interaction
        bias : torch.Tensor
            a torch.Tensor with randomly initialized values for each signaling network node
        """
        
        network_targets = self.edge_list[0].numpy() # the target nodes receiving an edge
        n_interactions = len(network_targets)

        set_seeds(self.seed)
        weight_values = 0.1 + 0.1*torch.rand(n_interactions, dtype=self.dtype, device = self.device)
        weight_values[self.edge_MOA[1,:]] = -weight_values[self.edge_MOA[1,:]] # make those that are inhibiting negative
        
        bias = 1e-3*torch.ones((self.n_network_nodes_in, 1), dtype = self.dtype, device = self.device)
        
        for nt_idx in np.unique(network_targets):
            if torch.all(weight_values[network_targets == nt_idx]<0):
                bias.data[nt_idx] = 1
    
        return weight_values, bias

    def make_mask(self):
        """Generates a mask for adjacency matrix for non-interacting nodes.

        Returns
        -------
        weights_mask : torch.Tensor
            a boolean adjacency matrix of all nodes in the signaling network, masking (True) interactions that are not present
        """

        weights_mask = torch.zeros(self.n_network_nodes, self.n_network_nodes, dtype=bool, device = self.device) # adjacency list format (targets (rows)--> sources (columns))
        weights_mask[self.edge_list] = True # if interaction is present, do not mask
        weights_mask = torch.logical_not(weights_mask) # make non-interacting edges False and vice-vesa
        return weights_mask

    def initialize_weights(self):
        """Initializes weights and masks for interacting nodes and mechanism of action.

        Returns
        -------
        weights : torch.Tensor
            a torch.Tensor adjacency matrix with randomly initialized values for each signaling network interaction
        bias : torch.Tensor
            a torch.Tensor with randomly initialized values for each signaling network node
        """

        weight_values, bias = self.initialize_weight_values()
        self.mask = self.make_mask()
        weights = torch.zeros(self.mask.shape, dtype = self.dtype, device = self.device) # adjacency matrix
        weights[self.edge_list] = weight_values
        
        return weights, bias

    def make_mask_MOA(self):
        """Generates mask (and weights) for adjacency matrix for non-interacting nodes AND nodes were mode of action (stimulating/inhibiting) 
        is unknown.

        Returns
        -------
        weights_MOA : torch.Tensor
            an adjacency matrix of all nodes in the signaling network, with activating interactions set to 1, inhibiting interactions set 
            to -1, and interactions that do not exist or have an unknown mechanism of action (stimulating/inhibiting) set to 0
        mask_MOA : torch.Tensor
            a boolean adjacency matrix of all nodes in the signaling network, with interactions that do not exist or have an unknown 
            mechanism of action masked (True)
        """
    
        signed_MOA = self.edge_MOA[0, :].type(torch.long) - self.edge_MOA[1, :].type(torch.long) #1=activation -1=inhibition, 0=unknown
        weights_MOA = torch.zeros(self.n_network_nodes_out, self.n_network_nodes_in, dtype=torch.long, device = self.device) # adjacency matrix
        weights_MOA[self.edge_list] = signed_MOA
        mask_MOA = weights_MOA == 0

        return weights_MOA, mask_MOA

    def prescale_weights(self, target_radius: float = 0.8):
        """Scale weights according to spectral radius
    
        Parameters
        ----------
        target_radius : float, optional
            _description_, by default 0.8
        """

        A = scipy.sparse.csr_matrix(self.weights.detach().cpu().numpy())
        np.random.seed(self.seed)
        eigen_value, _ = eigs(A, k = 1, v0 = np.random.rand(A.shape[0])) # first eigen value
        spectral_radius = np.abs(eigen_value)
        
        factor = target_radius/spectral_radius.item()
        self.weights.data = self.weights.data * factor

    def forward(self, X_full: torch.Tensor, X_cell: torch.Tensor):
        """Learn the edge weights within the signaling network topology.

        Parameters
        ----------
        X_full : torch.Tensor
            the linearly scaled ligand inputs. Shape is (samples x network nodes). Output of ProjectInput.
        X_cell : torch.Tensor
            the cell line input tensor. Shape is (samples x cell lines).
        Returns
        -------
        Y_full :  torch.Tensor
            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes).
        """

        X_bias = X_full.T + self.bias # this is the bias with the projection_amplitude included
        if self.cell_line_network is not None:
            cell_line_bias = self.cell_line_network(X_cell)
            #X_bias = X_bias + cell_line_bias.T  # Add the cell line bias term
            gate = torch.sigmoid(cell_line_bias)  # scale outputs between 0 and 1
            X_bias = X_bias + gate.T * cell_line_bias.T  # modulate the bias contribution
        
        if self.xss_cell_line_network is not None:
            X_new = self.xss_cell_line_network(X_cell).T  # initialize at cell line steady state
        else:
            X_new = torch.zeros_like(X_bias)  # initialize all values at 0
        
        # Initialize array to store all predictions
        X_new_list = []
        cnt = 0
        for t in range(self.training_params['max_steps']): # like an RNN, updating from previous time step
            X_old = X_new
            X_new = torch.mm(self.weights, X_new) # scale matrix by edge weights
            X_new = X_new + X_bias  # add original values and bias       
            X_new = self.activation(X_new, self.training_params['leak'])
            X_new_list.append(X_new)  # Store prediction of time step t
            if (t % 10 == 0) and (t > 20):
                diff = torch.max(torch.abs(X_new - X_old))    
                if diff.lt(self.training_params['tolerance']):
                    break
            cnt += 1
        
        # Pad with steady state values if time-loop breaks early
        for j in range(cnt, self.training_params['max_steps']-1):
            X_new_list.append(X_new)
        
        X_newFull = torch.stack(X_new_list, dim=2)  # structure time dimension by converting list of 2d tensors to 3d tensor
        Y_full = X_new.T
        Y_fullFull = X_newFull.permute(1, 2, 0)
        return Y_full, Y_fullFull
    
    def force_sparcity(self):
        self.weights.data.masked_fill_(mask = self.mask, value = 0.0) # fill non-interacting edges with 0
        
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        
        Parameters
        ----------
        lambda_2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
        
        Returns
        -------
        bionet_L2 : torch.Tensor
            the regularization term
        """
        bias_loss = lambda_L2 * torch.sum(torch.square(self.bias))
        weight_loss = lambda_L2 * torch.sum(torch.square(self.weights))

        bionet_L2 = bias_loss + weight_loss
        return bionet_L2
    
    def deprecation_L2_reg_zero(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        
        Parameters
        ----------
        lambda_2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
        
        Returns
        -------
        bionet_L2 : torch.Tensor
            the regularization term
        """


        bionet_L2_zero = lambda_L2 * torch.sum(1/(self.weights**2 + 0.5))

        return bionet_L2_zero
    def get_sign_mistmatch(self):
        """Identifies edge weights in network that have a sign that does not agree
        with the known mode of action.
    
        Mode of action: stimulating interactions are expected to have positive weights and inhibiting interactions
        are expected to have negative weights.
        
        Returns
        -------
        sign_mismatch : torch.Tensor
            a binary adjacency matrix of all nodes in the signaling network, where values are 1 if they do not 
            match the mode of action and 0 if they match the mode of action or have an unknown mode of action
        """
        sign_mismatch = torch.ne(torch.sign(self.weights), self.weights_MOA).type(self.dtype) 
        sign_mismatch = sign_mismatch.masked_fill(self.mask_MOA, 0) # do not penalize sign mismatches of unknown interactions
    
        return sign_mismatch

    def count_sign_mismatch(self):
        """Counts total sign mismatches identified in `get_sign_mistmatch`
        
        Returns
        -------
        n_sign_mismatches : float
            the total number of sign mismatches at `iter`
        """
        n_sign_mismatches = torch.sum(self.get_sign_mistmatch()).item()
        return n_sign_mismatches

    def sign_regularization(self, lambda_L1: Annotated[float, Ge(0)] = 0):
        """Get the L1 regularization term for the neural network parameters that 
        do not fit the mechanism of action (i.e., negative weights for stimulating interactions or positive weights for inhibiting interactions).
        Only penalizes sign mismatches of known MOA.
    
        Parameters
        ----------
        lambda_L1 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
    
        Returns
        -------
        loss : torch.Tensor
            the regularization term
        """
        lambda_L1 = torch.tensor(lambda_L1, dtype = self.dtype, device = self.device)
        sign_mismatch = self.get_sign_mistmatch() # will not penalize sign mismatches of unknown interactions

        loss = lambda_L1 * torch.sum(torch.abs(self.weights * sign_mismatch))
        return loss

    # def get_sign_mistmatch_edge_list(self):
    #     """Same as `get_sign_mistmatch`, but converts to coordinates corresponding to `edge_list`
        
    #     Returns
    #     -------
    #     sign_mismatch : torch.Tensor
    #         a binary vector corresponding to coordinates in `edge_list`, where values are 1 if they do not 
    #         match the mode of action and 0 if they match the mode of action or have an unknown mode of action
    #     """
    #     sign_mismatch = self.get_sign_mistmatch()
        
    #     # violations = sign_mismatch[self.edge_list] # 1 for interactions in edge list that mismatch, 0 otherwise
    #     # activation_mismatch = torch.logical_and(violations, self.edge_MOA[0])
    #     # inhibition_mismatch = torch.logical_and(violations, self.edge_MOA[1])
    #     # all_mismatch = torch.logical_or(activation_mismatch, inhibition_mismatch)
        
    #     sign_mismatch_edge = sign_mismatch[self.edge_list] # 1 for interactions in edge list that mismatch, 0 otherwise
        
    #     return sign_mismatch_edge
    def get_SS_loss(self, Y_full: torch.Tensor, spectral_loss_factor: float, subset_n: int = 10, **kwargs):
        """_summary_
    
        Parameters
        ----------
        Y_full : torch.Tensor
            output of the forward pass
            ensure to run `torch.Tensor.detach` method prior to inputting so that gradient calculations are not effected
        spectral_loss_factor : float
            _description_
        subset_n : int, optional
            _description_, by default 10
    
        Returns
        -------
        _type_
            _description_
        """
        spectral_loss_factor = torch.tensor(spectral_loss_factor, dtype=Y_full.dtype, device=Y_full.device)
        exp_factor = torch.tensor(self.training_params['exp_factor'], dtype=Y_full.dtype, device=Y_full.device)
    
        if self.seed:
            np.random.seed(self.seed + self._ss_seed_counter)
        selected_values = np.random.permutation(Y_full.shape[0])[:subset_n]
    
        SS_deviation, aprox_spectral_radius = self._get_SS_deviation(Y_full[selected_values,:], **kwargs)

        spectral_radius_factor = torch.exp(exp_factor*(aprox_spectral_radius-self.training_params['spectral_target']))
        
        loss = spectral_radius_factor * SS_deviation#/torch.sum(SS_deviation.detach())
        loss = spectral_loss_factor * torch.sum(loss)
        aprox_spectral_radius = torch.mean(aprox_spectral_radius).item()
    
        self._ss_seed_counter += 1 # new seed each time this (and _get_SS_deviation) is called
    
        return loss, aprox_spectral_radius
    
    def _get_SS_deviation(self, Y_full_sub, n_probes: int = 5, power_steps: int = 50):
        x_prime = self.onestepdelta_activation_factor(Y_full_sub, self.training_params['leak'])     
        x_prime = x_prime.unsqueeze(2)
        
        T = x_prime * self.weights
        if self.seed:
            set_seeds(self.seed + self._ss_seed_counter)
        delta = torch.randn((Y_full_sub.shape[0], Y_full_sub.shape[1], n_probes), dtype=Y_full_sub.dtype, device=Y_full_sub.device)
        for i in range(power_steps):
            new = delta / torch.norm(delta,dim=1).unsqueeze(1)
            delta = torch.matmul(T, new)

        new_delta = torch.matmul(T, delta)
        batch_eigen_not_norm=torch.einsum('ijk,ijk->ik',new_delta,delta)
        normalize=torch.einsum('ijk,ijk->ik',delta,delta)
        batch_SR_values,_=torch.max(torch.abs(batch_eigen_not_norm/normalize),axis=1) # spectral radius approx 

        aprox_spectral_radius = torch.mean(batch_SR_values, axis=0)      
        SS_deviation = batch_SR_values
    
        return SS_deviation, aprox_spectral_radius


class ProjectOutput(nn.Module):
    """Transforms signaling network to TF activity."""
    def __init__(self, node_idx_map: Dict[str, int], output_labels: np.array,
                    projection_amplitude: Union[int, float] = 1,
                    dtype: torch.dtype=torch.float32, device: str = 'cpu'):
        """Initialization method.
    
        Parameters
        ----------
        node_idx_map : Dict[str, int]
            a dictionary mapping node labels (str) to the node index (float)
            generated by `SignalingModel.parse_network`
        output_labels : np.array
           names of the out nodes (TFs) from net
        projection_amplitude : Union[int, float], optional
            value with which to initialize learned linear scaling parameters, by default 1. 
            (if turn require_grad = False for this layer, this is still applied  simply 
            as a constant linear scalar in each forward pass)
        dtype : torch.dtype, optional
            datatype to store values in torch, by default torch.float32
        device : str, optional
            whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
        """
        super().__init__()

        self.size_in = len(node_idx_map)
        self.size_out = len(output_labels)
        self.projection_amplitude = projection_amplitude

        self.output_node_order = torch.tensor([node_idx_map[x] for x in output_labels], device = device) # idx representation of TF outputs

        weights = self.projection_amplitude * torch.ones(len(output_labels), dtype=dtype, device = device)
        self.weights = nn.Parameter(weights)
        
        bias = torch.zeros(len(output_labels)).to(device, dtype)
        self.bias = nn.Parameter(bias)

    def deprecation_forward_no_bias(self, Y_full):
        """Like forward method, but does not include a bias term. This is like the original LEMBAS implementation."""
        Y_hat = self.weights * Y_full[:, self.output_node_order]
#         Y_hat = (self.weights * Y_full[:, self.output_node_order]) + self.bias
        return Y_hat
        
    def forward(self, Y_full):
        """Learn the weights for the output TFs of the signaling network (if grad_fn set to False, 
        simply scales by projection amplitude).
        Transforms full signaling network  (samples x network nodes) to only the space of the TFs.

        Parameters
        ----------
        Y_full : torch.Tensor
            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). 
            Output of BioNet.

        Returns
        -------
        Y_hat :  torch.Tensor
            the linearly scaled TF outputs. Shape is (samples x TFs)
        """
        Y_hat = (self.weights * Y_full[:, self.output_node_order]) + self.bias
        return Y_hat
    
    def deprecation_L2_reg_no_bias(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Like L2_reg, but if no bias is being used."""
        weight_loss = lambda_L2 * torch.sum(torch.square(self.weights - self.projection_amplitude)) 
        
        return weight_loss

    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):#
#                weights_lambda_L2: Annotated[float, Ge(0)] = 0, 
#               bias_lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        Here, this pushes learned parameters towards `projection_amplitude` 
        
        Parameters
        ----------
        weights_lambda_L2 : Annotated[float, Ge(0)]
            the regularization parameter for the weights, by default 0 (no penalty) 
        bias_lambda_L2 : Annotated[float, Ge(0)]
            the regularization parameter for the weights, by default 0 (no penalty) 
        
        Returns
        -------
        projection_L2 : torch.Tensor
            the regularization term
        """
#         weight_loss = weights_lambda_L2 * torch.sum(torch.square(self.weights - self.projection_amplitude)) 
#         biass_loss = bias_lambda_L2 * torch.sum(torch.square(self.bias))
#         return weight_loss + biass_loss
    
        weight_loss = lambda_L2 * torch.sum(torch.square(self.weights - self.projection_amplitude)) 
        bias_loss = lambda_L2 * torch.sum(torch.square(self.bias))
        return weight_loss + bias_loss

    # def set_device(self, device: str):
    #     """Sets torch.tensor objects to the device
        
    #     Parameters
    #     ----------
    #     device : str
    #         set to use gpu ("cuda") or cpu ("cpu")
    #     """
    #     self.output_node_order = self.output_node_order.to(device)


class NodesSitesMapping(nn.Module):
    """Layer to map signaling nodes to phosphosites with sparse connectivity.
       The connectivity is defined by nodes_sites_map, a binary (0/1) DataFrame of shape (n_sites, n_nodes).
       Only the connections indicated by 1 are learnable; we store these as a 1D parameter vector.
    """
    def __init__(self, nodes_sites_map: pd.DataFrame, hidden_layers: Dict[int, int] = None, dtype: torch.dtype = torch.float32, device: str = 'cpu', use_phospho: bool = True):
        """
        Parameters
        ----------
        nodes_sites_map : pd.DataFrame
            DataFrame with sites as rows and signaling nodes as columns.
            It must be one-hot (or sparse instead of dense) where 1 indicates a connection.
        dtype : torch.dtype, optional
            Data type for tensors.
        device : str, optional
            "cpu" or "cuda", by default "cpu".
        use_phospho : bool, optional
            Whether to use the phospho-specific weights, by default True.
        """
        super().__init__()
        self.device = device
        self.dtype = dtype

        # Convert mapping to a tensor and create the boolean mask
        mapping_tensor = torch.tensor(nodes_sites_map.values, dtype=self.dtype, device=self.device)
        self.mask = mapping_tensor != 0  # True where connection exists; shape: (n_sites, n_nodes)
        
        input_dim = nodes_sites_map.shape[1]  # Number of nodes
        output_dim = nodes_sites_map.shape[0]  # Number of sites

        layers = []
        prev_dim = input_dim
        
        # Add hidden layers if specified - Not used
        if hidden_layers:
            for i in range(1, len(hidden_layers) + 1):
                layers.append(nn.Linear(prev_dim, hidden_layers[i]).to(device, dtype))
                layers.append(nn.ReLU())
                prev_dim = hidden_layers[i]
        
        # Learnable parameter vector for the allowed weights (nonzero in the mask) and a bias parameter for each output
        n_nonzero = int(self.mask.sum().item())
        # Save the indices (row, col) where the mapping is 1
        self.indices = self.mask.nonzero(as_tuple=False)  # shape: (n_nonzero, 2)
        
        # Create a learnable vector for allowed connections
        if use_phospho:
            self.real_weights = nn.Parameter(torch.randn(n_nonzero, dtype=self.dtype, device=self.device)+1)
            self.bias = nn.Parameter(torch.zeros(output_dim, dtype=self.dtype, device=self.device))
        else:
            # Register as a buffer so it’s not trainable; it will remain ones
            self.register_buffer('real_weights', torch.ones(n_nonzero, dtype=self.dtype, device=self.device))
            self.register_buffer('bias', torch.zeros(output_dim, dtype=self.dtype, device=self.device))
        
        self.output_dim = output_dim

    def forward(self, Y_full: torch.Tensor):
        """
        Forward pass to map signaling nodes to phosphosites.
    
        Parameters
        ----------
        Y_full : torch.Tensor
            The signaling network output tensor. Shape (samples, time_points, n_nodes).
    
        Returns
        -------
        Y_mapped : torch.Tensor
            The mapped output tensor. Shape (samples, time_points, n_sites).
        """
        samples, time_points, nodes = Y_full.shape
        Y_full_reshaped = Y_full.view(samples * time_points, nodes)
        
        # Create a full weight matrix of shape (output_dim, n_nodes) filled with zeros
        full_weight = torch.zeros((self.output_dim, nodes), dtype=self.dtype, device=self.device)
        # Fill the allowed entries with the learnable weights
        full_weight[self.indices[:, 0], self.indices[:, 1]] = self.real_weights
        self.full_weight = full_weight
        Y_mapped_reshaped = torch.nn.functional.linear(Y_full_reshaped, full_weight, self.bias)
        Y_mapped = Y_mapped_reshaped.view(samples, time_points, -1)
        
        return Y_mapped


class NodesSitesMapping_embedding(nn.Module):
    """
     Alternative mapping layer that converts node-level outputs to phosphosite outputs.
    It first aggregates node outputs to site-level via a one-hot mapping (nodes_sites_map).
    Then, for each site, concatenates the aggregated scalar with a learned site embedding,
    and feeds the combined vector through an MLP to produce the final output.
    
    Input:
         Y_full: torch.Tensor of shape (samples, time_points, n_nodes)
    Output:
         Y_mapped: torch.Tensor of shape (samples, time_points, n_sites)
    """
    def __init__(self, nodes_sites_map: pd.DataFrame, conn_dim: int = 10,
                 hidden_layers: Dict[int, int] = None,
                 dtype: torch.dtype = torch.float32, device: str = 'cpu', use_phospho: bool = True):
        super().__init__()
        self.device = device
        self.dtype = dtype
        self.conn_dim = conn_dim

        self.n_sites = nodes_sites_map.shape[0]  # number of phosphosites
        self.n_nodes = nodes_sites_map.shape[1]  # number of signaling nodes
        
        self.mapping_tensor = torch.tensor(nodes_sites_map.values, dtype=self.dtype, device=self.device)

        # Create node embedding (nodes x conn_dim)
        self.site_embedding = nn.Parameter(torch.randn(self.n_sites, conn_dim, dtype=self.dtype, device=self.device))
        torch.nn.init.orthogonal_(self.site_embedding)  # Initialize with orthogonal matrix

        # Construct an MLP that maps from conn_dim to 1
        mlp_input_dim = 1 + conn_dim
        layers = []
        if hidden_layers:
            input_dim = mlp_input_dim
            for key in sorted(hidden_layers.keys()):
                layers.append(nn.Linear(input_dim, hidden_layers[key], bias=True))
                layers.append(nn.LeakyReLU())
                input_dim = hidden_layers[key]
            # Final layer outputs one scalar per site.
            layers.append(nn.Linear(input_dim, 1, bias=True))
        else:
            layers.append(nn.Linear(mlp_input_dim, 1, bias=True))
        
        self.non_linear = nn.Sequential(*layers).to(device, dtype)
        
    def forward(self, Y_full: torch.Tensor):
        """
        Forward pass.
        
        Parameters
        ----------
        Y_full : torch.Tensor
            Node-level outputs (samples, time_points, n_nodes)
        
        Returns
        -------
        Y_mapped : torch.Tensor
            Phosphosite outputs (samples, time_points, n_sites)
        """
        samples, time_points, _ = Y_full.shape
        
        B = samples * time_points
        
        site_agg = torch.matmul(Y_full, self.mapping_tensor.t())  # (samples, time_points, n_sites)
        site_agg_unsq = site_agg.unsqueeze(-1)  # (samples, time_points, n_sites, 1)
        emb_exp = self.site_embedding.unsqueeze(0).unsqueeze(0).expand(samples, time_points, self.n_sites, self.conn_dim)
        mlp_input = torch.cat((site_agg_unsq, emb_exp), dim=-1)
        
        B = samples * time_points * self.n_sites
        mlp_input_flat = mlp_input.view(B, -1)  # (B, 1 + conn_dim)
        mlp_output_flat = self.non_linear(mlp_input_flat)  # (B, 1)
        Y_mapped = mlp_output_flat.view(samples, time_points, self.n_sites)
        
        return Y_mapped

    def L2_reg(self, lambda_L2: float = 0.0):
        """
        Compute L2 regularization for the embedding and MLP layers.

        Parameters
        ----------
        lambda_L2 : float
            L2 regularization coefficient.

        Returns
        -------
        reg : torch.Tensor
            The L2 regularization term.
        """
        reg = 0.0

        # Regularize site embeddings
        reg += torch.sum(self.site_embedding ** 2)

        # Regularize MLP weights and biases
        for layer in self.non_linear:
            if isinstance(layer, nn.Linear):
                reg += torch.sum(layer.weight ** 2)
                if layer.bias is not None:
                    reg += torch.sum(layer.bias ** 2)

        return lambda_L2 * reg

'''class NodesSitesMapping_embedding_ka(nn.Module):
    """
    Revised mapping layer that converts signaling node outputs to phosphosite outputs.
    Here, a learnable node embedding (of shape (n_nodes, conn_dim)) is applied to the node outputs.
    The one-hot mapping (of shape (n_sites, n_nodes)) enforces allowed connections,
    combining node features (via a matrix multiply) into site features of shape (B, n_sites, conn_dim).
    Finally, an MLP (applied per site) nonlinearly maps the con‑dim features to a scalar output.
    """
    def __init__(self, nodes_sites_map: pd.DataFrame, conn_dim: int = 10,
                 hidden_layers: Dict[int, int] = None,
                 dtype: torch.dtype = torch.float32, device: str = 'cpu', use_phospho: bool = True):
        super().__init__()
        self.device = device
        self.dtype = dtype
        self.conn_dim = conn_dim

        n_sites = nodes_sites_map.shape[0]  # number of phosphosites
        n_nodes = nodes_sites_map.shape[1]  # number of signaling nodes
        self.output_dim = n_sites
        self.n_nodes = n_nodes

        # Create node embedding (nodes x conn_dim)
        self.node_embedding = nn.Parameter(torch.ones(n_nodes, conn_dim, dtype=self.dtype, device=self.device))
        torch.nn.init.orthogonal_(self.node_embedding)  # Initialize with orthogonal matrix

        # One-hot mapping (sites x nodes) to enforce allowed connections
        mapping_tensor = torch.tensor(nodes_sites_map.values, dtype=self.dtype, device=self.device)
        self.mapping_tensor = mapping_tensor  # shape: (n_sites, n_nodes)

        # Construct an MLP that maps from conn_dim to 1
        input_size = conn_dim
        layers = []
        if hidden_layers:
            for key in sorted(hidden_layers.keys()):
                layers.append(nn.Linear(input_size, hidden_layers[key], bias=True))
                layers.append(nn.ReLU())
                input_size = hidden_layers[key]
        # Final layer that outputs a single scalar per site
        layers.append(nn.Linear(input_size, 1, bias=True))
        self.non_linear = nn.Sequential(*layers).to(device, dtype)
        
    def forward(self, Y_full: torch.Tensor):
        """
        Forward pass.
        
        Parameters
        ----------
        Y_full : torch.Tensor
            Node-level outputs (samples, time_points, n_nodes)
        
        Returns
        -------
        Y_mapped : torch.Tensor
            Phosphosite outputs (samples, time_points, n_sites)
        """
        samples, time_points, n_nodes = Y_full.shape
        B = samples * time_points
        
        Y_flat = Y_full.view(B, n_nodes)  # (B, n_nodes)

        # Multiply node outputs with node embedding
        # For each node i: node feature = Y_flat[:, i] * node_embedding[i]
        node_features = Y_flat.unsqueeze(-1) * self.node_embedding  # (B, n_nodes, conn_dim)

        # Enforce allowed connections
        site_features = torch.matmul(self.mapping_tensor.float(), node_features)

        # Reshape to combine batch and site dimensions: (B * n_sites, conn_dim)
        mlp_input = site_features.view(B * self.output_dim, self.conn_dim)
        mlp_output = self.non_linear(mlp_input)  # shape: (B * n_sites, 1)
        
        # Reshape back to (B, n_sites)
        out = mlp_output.view(B, self.output_dim)
        Y_mapped = out.view(samples, time_points, self.output_dim)
        return Y_mapped'''


class CumsumMapping(nn.Module):
    def __init__(self, bionet_params: Dict[str, float], K: int = 8, use_time: bool = True):
        """
        Parameter
        ----------
        bionet_params : Dict[str, float]
            training parameters for the model, by default None
            Key values include:
                - 'max_steps': maximum number of time steps of the RNN, by default 300
                - 'tolerance': threshold at which to break RNN; based on magnitude of change of updated edge weight values, by default 1e-5
                - 'leak': parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01
                - 'spectral_target': _description_, by default np.exp(np.log(params['tolerance'])/params['target_steps'])
                - 'exp_factor': _description_, by default 20
        K : Int
            Number of training time points
        init : int, optional
            Seed for random initialization, by default None.
        """
        super().__init__()
        if use_time:
            self.L = bionet_params['max_steps']
            self.K = K
            
            # Initialize K raw parameters for increments.
            # We set the first element to a very low value (e.g., -3) so that softplus gives a small number,
            # and initialize the others to a constant so that softplus outputs ~1.
            self.delta_raw = nn.Parameter(torch.empty(K))
            nn.init.constant_(self.delta_raw, 0.541)  # so softplus(0.541) ≈ 1.0
                
            with torch.no_grad():
                self.delta_raw[0] = -3.0  # so softplus(-3.0) ≈ 0.05
            
            # Learnable parameter for the upper bound.
            # We want u to lie in (0, L), so we use a sigmoid scaling.
            self.u_raw = nn.Parameter(torch.tensor(0.0))  # initial u ~ L * sigmoid(0)=L/2
            
            # Learnable nonlinearity parameter alpha.
            # Initialize to a negative value to bias more anchors toward the beginning.
            self.alpha = nn.Parameter(torch.tensor(-1.0))
        else:
            self.L = 1
            self.K = 1
            self.register_buffer('delta_raw', torch.empty(K))
            self.register_buffer('u_raw', torch.tensor(0.0))
            self.register_buffer('alpha', torch.tensor(-1.0))
    
    def forward(self):
        """
        Returns
        -------
        mapping : torch.Tensor of shape (K,)
            Continuous mapping indices that lie in [0, u],
            where u is learnable and u < L.
        """
        L = self.L
        
        # Compute learnable upper bound u in (0, L)
        u = L * torch.sigmoid(self.u_raw)
        
        # Compute raw anchors from delta_raw:
        deltas = F.softplus(self.delta_raw)   # ensure positive increments
        anchors = torch.cumsum(deltas, dim=0)   # monotonic increasing
        # Shift so the first anchor is zero:
        anchors_shifted = anchors - anchors[0]
        
        # Normalize anchors to [0,1]:
        normalized = anchors_shifted / (anchors_shifted[-1] + 1e-8)
        
        # Apply a nonlinear mapping function:
        # mapping(x) = u * (exp(alpha*x) - 1) / (exp(alpha) - 1)
        # If alpha is near zero, fall back to linear mapping.
        eps = 1e-6
        if torch.abs(self.alpha) < eps:
            mapping = u * normalized
        else:
            mapping = u * (torch.exp(self.alpha * normalized) - 1) / (torch.exp(self.alpha) - 1)
        
        # Enforce that the mapping values are less than L.
        mapping = torch.clamp(mapping, 0, L - 1)
        return mapping
    
    def print_gradients(self):
        if self.delta_raw.grad is not None:
            print("Gradient of delta_raw:", self.delta_raw.grad)
        else:
            print("Gradient of delta_raw is None")
    
class SignalingModel(torch.nn.Module):
    """Constructs the signaling network based RNN."""
    DEFAULT_TRAINING_PARAMETERS = {'target_steps': 100, 'max_steps': 300, 'exp_factor': 20, 'leak': 0.01, 'tolerance': 1e-5}
    
    def __init__(self, net: pd.DataFrame, X_in: pd.DataFrame, y_out: pd.DataFrame, X_cell: pd.DataFrame, X_drug: pd.DataFrame, nodes_sites_map: pd.DataFrame,
                 projection_amplitude_in: Union[int, float] = 1, projection_amplitude_out: float = 1,
                 ban_list: List[str] = None, weight_label: str = 'mode_of_action', 
                 source_label: str = 'source', target_label: str = 'target', 
                 bionet_params: Dict[str, float] = None, 
                 activation_function: str='MML', dtype: torch.dtype=torch.float32, device: str = 'cpu', seed: int = 888, 
                 module_params: Dict[str, Any] = None):
                 #use_cell_line_network: bool = True, hidden_layers: Dict[int, int] = None, n_timepoints: int = 8
        """Parse the signaling network and build the model layers.

        Parameters
        ----------
        net: pd.DataFrame
            signaling network adjacency list with the following columns:
                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1). Exclude non-interacting (0) nodes. 
                - `source_label`: source node column name
                - `target_label`: target node column name
        X_in : pd.DataFrame
            input ligand concentrations. Index represents samples and columns represent drugs. Values represent amount of drug introduced (e.g., concentration). 
        y_out : pd.DataFrame
            output TF activities. Index represents samples and columns represent phosphosites. Values represent activity of the TF. 
        X_cell : pd.DataFrame
            One hot encoded cell types.  Index represents samples and columns represent cell types.
        X_drug : pd.DataFrame
            One hot encoded drug targets.  Index represents drug targets and columns represent drugs.
        nodes_sites_map : pd.DataFrame
            Nodes to sites mapping.  Index represents phosphosites and columns represent signaling nodes.
        ban_list : List[str], optional
            a list of signaling network nodes to disregard, by default None
        projection_amplitude_in : Union[int, float]
            value with which to scale ligand inputs by, by default 1 (see `ProjectInput` for details, can also be tuned as a learned parameter in the model)
        projection_amplitude_out : float
             value with which to scale TF activity outputs by, by default 1 (see `ProjectOutput` for details, can also be tuned as a learned parameter in the model)
        bionet_params : Dict[str, float], optional
            training parameters for the model, by default None
            Key values include:
                - 'max_steps': maximum number of time steps of the RNN, by default 300
                - 'tolerance': threshold at which to break RNN; based on magnitude of change of updated edge weight values, by default 1e-5
                - 'leak': parameter to tune extent of leaking, analogous to leaky ReLU, by default 0.01
                - 'spectral_target': _description_, by default np.exp(np.log(params['tolerance'])/params['target_steps'])
                - 'exp_factor': _description_, by default 20
        activation_function : str, optional
            RNN activation function, by default 'MML'
            options include:
                - 'MML': Michaelis-Menten-like
                - 'leaky_relu': Leaky ReLU
                - 'sigmoid': sigmoid 
        dtype : torch.dtype, optional
            datatype to store values in torch, by default torch.float32
        device : str
            whether to use gpu ("cuda") or cpu ("cpu"), by default "cpu"
        seed : int
            random seed for torch and numpy operations, by default 888
        module_params : Dict[str, Any], optional 
            parameters for the extra modules created for the time-series phosphoproteome problem, by default None
            Key values included:
                - 'use_cln' : whether to use the cell line network, by default True
                - 'cln_hidden_layers': Dictionary specifying the number of hidden layers and their sizes. Keys are layer indices (starting from 1) and values are the number of neurons.
                - 'n_timepoints': Number of time points in the training dataset
        """
        super().__init__()
        self.dtype = dtype
        self.device = device
        self.seed = seed
        self._gradient_seed_counter = 0
        self.projection_amplitude_out = projection_amplitude_out

        edge_list, node_labels, edge_MOA = self.parse_network(net, ban_list, weight_label, source_label, target_label)
                
        # Save edge_list to a .txt file
        #np.savetxt("edge_list.txt", edge_list, fmt='%s', delimiter='\t')  # Adjust fmt and delimiter as needed

        if not bionet_params:
            bionet_params = self.DEFAULT_TRAINING_PARAMETERS.copy()
        else:
            bionet_params = self.set_training_parameters(**bionet_params)

        # Access the parameters of the new modules | time series mapping, cell line encoding
        use_cln = module_params['use_cln']
        cln_hidden_layers = module_params['cln_hidden_layers']
        use_xssn = module_params['use_xssn']
        xssn_hidden_layers = module_params['xssn_hidden_layers']
        nsl_hidden_layers = module_params['nsl_hidden_layers']
        n_timepoints = module_params['n_timepoints']
        use_time = module_params['use_time']
        use_phospho = module_params['use_phospho']
        conn_dim = module_params['conn_dim']
        
        # filter for nodes in the network, sorting by node_labels order
        self.X_in = X_in
        self.X_drug = X_drug.loc[np.intersect1d(X_drug.index.values, node_labels), :]
        
        #self.y_out = y_out.loc[:, np.intersect1d(y_out.columns.values, node_labels)]
        intersecting_nodes = np.intersect1d(nodes_sites_map.columns.values, node_labels)
        self.y_out = y_out.loc[:, nodes_sites_map[intersecting_nodes].index]  # Map the right nodes to the right sites
        self.X_cell = X_cell
        self.nodes_sites_map = nodes_sites_map
        self.node_labels = node_labels
        
        # define model layers
        self.input_layer = ProjectInput(node_idx_map = self.node_idx_map, 
                                        drug_target_map = self.X_drug, 
                                        projection_amplitude = projection_amplitude_in, 
                                        dtype = self.dtype, 
                                        device = self.device)
        
        self.signaling_network = BioNet(edge_list = edge_list, 
                                        edge_MOA = edge_MOA, 
                                        n_network_nodes = len(node_labels), 
                                        bionet_params = bionet_params, 
                                        activation_function = activation_function, 
                                        dtype = self.dtype, device = self.device, seed = self.seed,
                                        cell_line_network = CellLineNetwork(input_dim=X_cell.shape[1], hidden_layers=cln_hidden_layers, output_dim=len(node_labels), dtype=self.dtype, device=self.device) if use_cln else None,
                                        xss_cell_line_network = XssCellLineNetwork(input_dim=X_cell.shape[1], hidden_layers=xssn_hidden_layers, output_dim=len(node_labels), dtype=self.dtype, device=self.device) if use_xssn else None)
        
        self.output_layer = ProjectOutput(node_idx_map = self.node_idx_map, 
                                          output_labels = self.nodes_sites_map.columns.values, 
                                          projection_amplitude = self.projection_amplitude_out, 
                                          dtype = self.dtype, device = device)
        
        if conn_dim is not None:
            self.nodes_sites_layer = NodesSitesMapping_embedding(nodes_sites_map = self.nodes_sites_map,
                                                   conn_dim = conn_dim,
                                                   hidden_layers = nsl_hidden_layers,
                                                   dtype = self.dtype, 
                                                   device = self.device,
                                                   use_phospho = use_phospho)
        else:
            self.nodes_sites_layer = NodesSitesMapping(nodes_sites_map = self.nodes_sites_map,
                                                    hidden_layers = nsl_hidden_layers,
                                                    dtype = self.dtype, 
                                                    device = self.device,
                                                    use_phospho = use_phospho)
        
        self.time_layer = CumsumMapping(bionet_params = bionet_params, K = n_timepoints, use_time = use_time)
        
    def parse_network(self, net: pd.DataFrame, ban_list: List[str] = None, 
                 weight_label: str = 'mode_of_action', source_label: str = 'source', target_label: str = 'target'):
        """Parse adjacency network.
    
        Parameters
        ----------
        net: pd.DataFrame
            signaling network adjacency list with the following columns:
                - `weight_label`: whether the interaction is stimulating (1) or inhibiting (-1) or unknown (0). Exclude non-interacting (0)
                nodes. 
                - `source_label`: source node column name
                - `target_label`: target node column name
        ban_list : List[str], optional
            a list of signaling network nodes to disregard, by default None
    
        Returns
        -------
        edge_list : np.array
            a (2, net.shape[0]) array where the first row represents the indices for the target node and the 
            second row represents the indices for the source node. net.shape[0] is the total # of interactions
        node_labels : list
            a list of the network nodes in the same order as the indices
        edge_MOA : np.array
            a (2, net.shape[0]) array where the first row is a boolean of whether the interactions are stimulating and the 
            second row is a boolean of whether the interactions are inhibiting. 
            
            Note: Edge_list includes interactions that are not delineated as activating OR inhibiting, s.t. edge_MOA records this 
            as [False, False].
        """
        if not ban_list:
            ban_list = []
        if sorted(net[weight_label].unique()) != [-1, 0.1, 1] and sorted(net[weight_label].unique()) != [-1, 1]:  # Change the statement in case we do not have missing values | synthetic dataset
            raise ValueError(weight_label + ' values must be 1 or -1')
        
        net = net[~ net[source_label].isin(ban_list)]
        net = net[~ net[target_label].isin(ban_list)]

        # create an edge list with node incides
        node_labels = sorted(pd.concat([net[source_label], net[target_label]]).unique())
        self.node_idx_map = {idx: node_name for node_name, idx in enumerate(node_labels)}
        
        source_indices = net[source_label].map(self.node_idx_map).values
        target_indices = net[target_label].map(self.node_idx_map).values

        # # get edge list
        # edge_list = np.array((target_indices, source_indices))
        # edge_MOA = net[weight_label].values
        # get edge list *ordered by source-target node index*
        n_nodes = len(node_labels)
        A = scipy.sparse.csr_matrix((net[weight_label].values, (source_indices, target_indices)), shape=(n_nodes, n_nodes)) # calculate adjacency matrix
        source_indices, target_indices, edge_MOA = scipy.sparse.find(A) # re-orders adjacency list by index
        edge_list = np.array((target_indices, source_indices)) 
        edge_MOA = np.array([[edge_MOA==1],[edge_MOA==-1]]).squeeze() # convert to boolean

        return edge_list, node_labels, edge_MOA

    def df_to_tensor(self, df: pd.DataFrame):
        """Converts a pandas dataframe to the appropriate torch.tensor"""
        return torch.tensor(df.values.copy(), dtype=self.dtype, device = self.device)

    def set_training_parameters(self, **attributes):
        """Set the parameters for training the model. Overrides default parameters with attributes if specified.
        Adapted from LEMBAS `trainingParameters`
    
        Parameters
        ----------
        attributes : dict
            keys are parameter names and values are parameter value
        """
        #set defaults
        default_parameters = self.DEFAULT_TRAINING_PARAMETERS.copy()
        allowed_params = list(default_parameters.keys()) + ['spectral_target']
    
        params = {**default_parameters, **attributes}
        if 'spectral_target' not in params.keys():
            params['spectral_target'] = np.exp(np.log(params['tolerance'])/params['target_steps'])
    
        params = {k: v for k,v in params.items() if k in allowed_params}
    
        return params
    
    def forward(self, X_in, X_cell, missing_indexes):
        """Linearly scales ligand inputs, learns weights for signaling network interactions, and transforms this to TF activity. See
        `forward` methods of each layer for details."""
        X_full = self.input_layer(X_in) # input ligands to signaling network
        Y_full, Y_fullFull = self.signaling_network(X_full, X_cell) # RNN of full signaling network
        
        Y_fullprotein = Y_fullFull
        # Mask for non-overlapping signaling nodes  with PKN before mapping to phosphosites
        mask = torch.tensor([i not in missing_indexes for i in range(len(self.node_labels))])
        Y_fullFull = Y_fullFull[:, :, mask]
        Y_fullFull = self.nodes_sites_layer(Y_fullFull)  # Map signaling nodes to phosphosites
        Y_hat = self.output_layer(Y_full) # TF outputs of signaling network
        return Y_hat, Y_full, Y_fullFull, Y_fullprotein
    
    def L2_reg(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the neural network parameters.
        
        Parameters
        ----------
        lambda_L2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
         output_bias_lambda_L2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty)         
        
        Returns
        -------
         : torch.Tensor
            the regularization term (as the sum of the regularization terms for each layer)
        """
        return self.input_layer.L2_reg(lambda_L2) + self.signaling_network.L2_reg(lambda_L2) + self.output_layer.L2_reg(lambda_L2) + self.nodes_sites_layer.L2_reg(lambda_L2)

    def ligand_regularization(self, lambda_L2: Annotated[float, Ge(0)] = 0):
        """Get the L2 regularization term for the ligand biases. Intuitively, extracellular ligands should not contribute to 
        "baseline (i.e., unstimulated) activity" affecting intrecllular signaling nodes and thus TF outputs.
        
        Parameters
        ----------
        lambda_L2 : Annotated[float, Ge(0)]
            the regularization parameter, by default 0 (no penalty) 
        
        Returns
        -------
        loss : torch.Tensor
            the regularization term
        """
        loss = lambda_L2 * torch.sum(torch.square(self.signaling_network.bias[self.input_layer.input_node_order]))
        return loss

    def uniform_regularization(self, lambda_L2: float, Y_full: torch.Tensor, 
                     target_min: float = 0.0, target_max: float = None):
        """Get the L2 regularization term for deviations of the nodes in Y_full from that of a uniform distribution between 
        `target_min` and `target_max`. 
        Note, this penalizes both deviations from the uniform distribution AND values that are out of range (like a double penalty).
    
        Parameters
        ----------
        lambda_L2 : float
            scaling factor for state loss
        Y_full : torch.Tensor
            the signaling network scaled by learned interaction weights. Shape is (samples x network nodes). 
            Output of BioNet.
        target_min : float, optional
            minimum values for nodes in Y_full to take on, by default 0.0
        target_max : float, optional
            maximum values for nodes in Y_full to take on, by default 1/`self.projection_amplitude_out`
    
        Returns
        -------
        loss : torch.Tensor
            the regularization term
        """
        lambda_L2 = torch.tensor(lambda_L2, dtype = Y_full.dtype, device = Y_full.device)
        # loss = lambda_L2 * expected_uniform_distribution(Y_full, target_max = 1/self.projectionAmplitude)
        if not target_max:
            target_max = 1/self.projection_amplitude_out
        
        sorted_Y_full, _ = torch.sort(Y_full, axis=0) # sorts each column (signaling network node) in ascending order
        target_distribution = torch.linspace(target_min, target_max, Y_full.shape[0], dtype=Y_full.dtype, device=Y_full.device).reshape(-1, 1)
        
        dist_loss = torch.sum(torch.square(sorted_Y_full - target_distribution)) # difference in distribution
        below_loss = torch.sum(Y_full.lt(target_min) * torch.square(Y_full-target_min)) # those that are below the minimum value
        above_loss = torch.sum(Y_full.gt(target_max) * torch.square(Y_full-target_max)) # those that are above the maximum value
        loss = lambda_L2*(dist_loss + below_loss + above_loss)
        return loss
    
    def deprecation_parametric_uniform_regularization(self, lambda_L2: float, Y_full: torch.Tensor, 
                                          target_min: float = 0.0, target_max: float = None, max_constraint_factor: int = 50):

        """Parametric alternative to uniform_regularization function above."""
        lambda_L2 = torch.tensor(lambda_L2, dtype=Y_full.dtype, device=Y_full.device)
        # loss = lambda_L2 * expected_uniform_distribution(Y_full_, target_max = 1/self.projectionAmplitude)
        if not target_max:
            target_max = 1 / self.projection_amplitude_out

        Y_full_ = Y_full.detach().clone()  # note, this is not done in the typical uniform regularization
        target_mean = (target_max - target_min) / 2
        target_var = (target_max - target_min) ** 2 / 12

        factor = 1
        mean_factor = factor
        var_factor = factor
        min_factor = factor
        max_factor = factor
        max_constraint_factor = factor * max_constraint_factor

        node_mean = torch.mean(Y_full_, dim=0)
        node_var = torch.mean(torch.square(Y_full_ - node_mean), dim=0)
        max_val, _ = torch.max(Y_full_, dim=0)
        min_val, _ = torch.min(Y_full_, dim=0)

        mean_loss = mean_factor * torch.sum(torch.square(node_mean - target_mean))
        var_loss = var_factor * torch.sum(torch.square(node_var - target_var))
        max_loss = max_factor * torch.sum(torch.square(max_val - target_max))
        min_loss = min_factor * torch.sum(torch.square(min_val - target_min))
        max_constraint = -max_constraint_factor * torch.sum(max_val[max_val.detach() <= 0])  # max value should never be negative

        loss = mean_loss + var_loss + min_loss + max_loss + max_constraint

        return lambda_L2 * loss

    def add_gradient_noise(self, noise_level: Union[float, int], cur_lr: float):
        """Adds noise to backwards pass gradient calculations. Use during training to make model more robust. 
    
        Parameters
        ----------
        noise_level : Union[float, int]
            scaling factor for amount of noise to add 
        """
        all_params = list(self.parameters())
        if self.seed:
            set_seeds(self.seed + self._gradient_seed_counter)
        for i in range(len(all_params)):
            if all_params[i].requires_grad:
                all_noise = torch.randn(all_params[i].grad.shape, dtype=all_params[i].dtype, device=all_params[i].device)
                all_params[i].grad += (noise_level * (cur_lr**2) * all_noise)
    
        self._gradient_seed_counter += 1 # new random noise each time function is called

    def copy(self):
        return copy.deepcopy(self)